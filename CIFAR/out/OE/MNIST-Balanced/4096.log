ic| len(dset): 60000
ic| len(dset): 10000
{'dataset': 'MNIST', 'model': 'densenet', 'calibration': False, 'epochs': 100, 'learning_rate': 0.001, 'batch_size': 128, 'oe_batch_size': 256, 'test_bs': 200, 'momentum': 0.9, 'decay': 0.0005, 'layers': 40, 'widen_factor': 2, 'droprate': 0.3, 'save': './snapshots/oe_tune', 'load': './snapshots/pretrained', 'test': False, 'ngpu': 1, 'prefetch': 1, 'm_in': -25.0, 'm_out': -7.0, 'score': 'OE', 'seed': 1, 'regime': 'Balanced', 'n_ood': 4096}
torch.Size([8192, 1, 28, 28])
Counter({8: 4096, 9: 4096})
Tesla V100-PCIE-16GB
Model restored!
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:00<00:15,  4.01it/s]  8%|▊         | 5/63 [00:00<00:03, 16.10it/s] 14%|█▍        | 9/63 [00:00<00:02, 22.99it/s] 21%|██        | 13/63 [00:00<00:01, 27.32it/s] 27%|██▋       | 17/63 [00:00<00:01, 30.14it/s] 33%|███▎      | 21/63 [00:00<00:01, 32.03it/s] 40%|███▉      | 25/63 [00:00<00:01, 33.29it/s] 46%|████▌     | 29/63 [00:01<00:00, 34.18it/s] 52%|█████▏    | 33/63 [00:01<00:00, 34.80it/s] 59%|█████▊    | 37/63 [00:01<00:00, 35.22it/s] 65%|██████▌   | 41/63 [00:01<00:00, 35.52it/s] 71%|███████▏  | 45/63 [00:01<00:00, 35.72it/s] 78%|███████▊  | 49/63 [00:01<00:00, 35.87it/s] 84%|████████▍ | 53/63 [00:01<00:00, 35.98it/s] 90%|█████████ | 57/63 [00:01<00:00, 36.06it/s] 97%|█████████▋| 61/63 [00:01<00:00, 36.12it/s]100%|██████████| 63/63 [00:01<00:00, 32.08it/s]
0.9972718253968254
0.010138743690890444
0.9972558313583637
Beginning Training

/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch   1 | Time    10 | Train Loss 1.6901 | Test Loss 0.013 | Test Error 0.31
Epoch   2 | Time     9 | Train Loss 1.3005 | Test Loss 0.016 | Test Error 0.39
Epoch   3 | Time     9 | Train Loss 1.1803 | Test Loss 0.023 | Test Error 0.44
Epoch   4 | Time     9 | Train Loss 1.1494 | Test Loss 0.026 | Test Error 0.46
Epoch   5 | Time     9 | Train Loss 1.1310 | Test Loss 0.026 | Test Error 0.47
Epoch   6 | Time     9 | Train Loss 1.1260 | Test Loss 0.026 | Test Error 0.44
Epoch   7 | Time     9 | Train Loss 1.1179 | Test Loss 0.026 | Test Error 0.42
Epoch   8 | Time     9 | Train Loss 1.1112 | Test Loss 0.026 | Test Error 0.40
Epoch   9 | Time     9 | Train Loss 1.1109 | Test Loss 0.027 | Test Error 0.39
Epoch  10 | Time     9 | Train Loss 1.1057 | Test Loss 0.026 | Test Error 0.39
Epoch  11 | Time     9 | Train Loss 1.1011 | Test Loss 0.026 | Test Error 0.37
Epoch  12 | Time     9 | Train Loss 1.0967 | Test Loss 0.025 | Test Error 0.35
Epoch  13 | Time     9 | Train Loss 1.1062 | Test Loss 0.024 | Test Error 0.34
Epoch  14 | Time     9 | Train Loss 1.1017 | Test Loss 0.025 | Test Error 0.36
Epoch  15 | Time     9 | Train Loss 1.0929 | Test Loss 0.024 | Test Error 0.32
Epoch  16 | Time     9 | Train Loss 1.0892 | Test Loss 0.024 | Test Error 0.32
Epoch  17 | Time     9 | Train Loss 1.0939 | Test Loss 0.024 | Test Error 0.32
Epoch  18 | Time     9 | Train Loss 1.0929 | Test Loss 0.023 | Test Error 0.32
Epoch  19 | Time     9 | Train Loss 1.0914 | Test Loss 0.023 | Test Error 0.32
Epoch  20 | Time     9 | Train Loss 1.0885 | Test Loss 0.022 | Test Error 0.34
Epoch  21 | Time     9 | Train Loss 1.0839 | Test Loss 0.022 | Test Error 0.34
Epoch  22 | Time     9 | Train Loss 1.0894 | Test Loss 0.022 | Test Error 0.31
Epoch  23 | Time     9 | Train Loss 1.0825 | Test Loss 0.022 | Test Error 0.32
